# Chapter 12  Networked programs

## 12.1 Hypertext Transfer Protocol - HTTP

* **Transport control protocol (TCP)**
   * Built on top of IP (Internet Protocol)
   * Assumes IP might lose some data stores

* **socket** : built-in support in Python

   * like a file
   
   * A single socket provides a two-way connection between two programs. You can read from and write to the same socket.


## 12.2 The world's simplest web browser

```python
>>> import socket
>>> mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> mysock.connect(('data.pr4e.org', 80))    # make a connection to port 80 on the server www.py4e.com
>>> cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\r\n\r\n'.encode()  
# \r\n signifies an EOL (end of line), \r\n\r\n signifies nothing between two EOL, the equivalent of a blank line
>>> mysock.send(cmd)
47
>>> while True:
...     data = mysock.recv(512)    # recv() returns an empty string
...     if len(data) < 1:
...         break
...     print(data.decode(),end='')
... 
HTTP/1.1 200 OK
Date: Fri, 12 Mar 2021 03:55:08 GMT
Server: Apache/2.4.18 (Ubuntu)
Last-Modified: Sat, 13 May 2017 11:22:22 GMT
ETag: "a7-54f6609245537"
Accept-Ranges: bytes
Content-Length: 167
Cache-Control: max-age=0, no-cache, no-store, must-revalidate
Pragma: no-cache
Expires: Wed, 11 Jan 1984 05:00:00 GMT
Connection: close
Content-Type: text/plain

But soft what light through yonder window breaks
It is the east and Juliet is the sun
Arise fair sun and kill the envious moon
Who is already sick and pale with grief
>>> mysock.close()
>>> 
```
*  encode() and decode() methods convert strings into bytes objects and back again
   * a bytes object.encode() and b'' are equivalent
```
>>> b'Hello world'
b'Hello world'
>>> 'Hello world'.encode()
b'Hello world'
```

## 12.3 Retrieving an image over HTTP









## 12.4 Retrieving web pages with urllib

## 12.5 Reading binary files using urllib

## 12.6 Parsing HTML and scraping the web

## 12.7 Parsing HTML using regular expressions

## 12.8 Parsing HTML using BeautifulSoup

## 12.9 Bonus section for Unix / Linux users

## 12.10 Glossary

BeautifulSoup A Python library for parsing HTML documents and extracting data from HTML documents that compensates for most of the imperfections in the HTML that browsers generally ignore. You can download the Beauti- fulSoup code from www.crummy.com.

port A number that generally indicates which application you are contacting when you make a socket connection to a server. As an example, web traffic usually uses port 80 while email traffic uses port 25.

scrape When a program pretends to be a web browser and retrieves a web page, then looks at the web page content. Often programs are following the links in one page to find the next page so they can traverse a network of pages or a social network.

socket A network connection between two applications where the applications can send and receive data in either direction.

spider The act of a web search engine retrieving a page and then all the pages linked from a page and so on until they have nearly all of the pages on the Internet which they use to build their search index.

## 12.11 Exercises

Exercise 1: Change the socket program socket1.py to prompt the user for the URL so it can read any web page. You can use split('/') to break the URL into its component parts so you can extract the host name for the socket connect call. Add error checking using try and except to handle the condition where the user enters an improperly formatted or non-existent URL.


Exercise 2: Change your socket program so that it counts the number of characters it has received and stops displaying any text after it has shown 3000 characters. The program should retrieve the entire docu- ment and count the total number of 
characters and display the count of the number of characters at the end of the document.


Exercise 3: Use urllib to replicate the previous exercise of (1) retrieving the document from a URL, (2) displaying up to 3000 characters, and (3) counting the overall number of characters in the document. Donâ€™t worry about the headers for this exercise, simply show the first 3000 characters of the document contents.


Exercise 4: Change the urllinks.py program to extract and count para- graph (p) tags from the retrieved HTML document and display the count of the paragraphs as the output of your program. Do not display the paragraph text, only count them. Test your program on several small web pages as well as some larger web pages.


Exercise 5: (Advanced) Change the socket program so that it only shows data after the headers and a blank line have been received. Remember that recv receives characters (newlines and all), not lines.
